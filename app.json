[{"name":"app.R","content":"# Text Mining Tutorial in R - Shinylive Version\n# This version includes fallbacks for missing packages\n\n# Install missing packages if needed (uncomment as necessary)\n# install.packages(c(\"shiny\", \"shinydashboard\", \"DT\", \"shinyAce\", \"tm\", \n#                    \"tidytext\", \"wordcloud\", \"RColorBrewer\", \"ggplot2\", \n#                    \"dplyr\", \"stringr\", \"plotly\", \"SnowballC\"))\n\n# Load required libraries with error handling\nrequired_packages <- c(\"shiny\", \"shinydashboard\", \"DT\", \"tm\", \"tidytext\", \n                      \"wordcloud\", \"RColorBrewer\", \"ggplot2\", \"dplyr\", \n                      \"stringr\", \"plotly\", \"SnowballC\")\n\n# Try to load shinyAce, use fallback if not available\nuse_ace <- FALSE\nif (requireNamespace(\"shinyAce\", quietly = TRUE)) {\n  library(shinyAce)\n  use_ace <- TRUE\n  message(\"Using shinyAce for code editing\")\n} else {\n  message(\"shinyAce not available - using text areas instead\")\n}\n\n# Load other packages\nfor (pkg in required_packages) {\n  if (requireNamespace(pkg, quietly = TRUE)) {\n    library(pkg, character.only = TRUE)\n  } else {\n    warning(paste(\"Package\", pkg, \"not available\"))\n  }\n}\n\n# Function to create code input (with fallback)\ncreate_code_input <- function(id, value = \"\", height = \"200px\") {\n  if (use_ace) {\n    aceEditor(id, value = value, mode = \"r\", height = height)\n  } else {\n    textAreaInput(id, label = NULL, value = value, \n                 width = \"100%\", height = height,\n                 placeholder = \"Enter your R code here...\")\n  }\n}\n\n# Define UI\nui <- dashboardPage(\n  dashboardHeader(title = \"Learn Text Mining in R - Interactive Tutorial\"),\n  \n  dashboardSidebar(\n    sidebarMenu(\n      menuItem(\"Getting Started\", tabName = \"intro\", icon = icon(\"play-circle\")),\n      menuItem(\"Text Basics\", tabName = \"basics\", icon = icon(\"font\")),\n      menuItem(\"Text Preprocessing\", tabName = \"preprocessing\", icon = icon(\"broom\")),\n      menuItem(\"Word Frequency\", tabName = \"frequency\", icon = icon(\"chart-bar\")),\n      menuItem(\"Word Clouds\", tabName = \"wordcloud\", icon = icon(\"cloud\")),\n      menuItem(\"Sentiment Analysis\", tabName = \"sentiment\", icon = icon(\"smile\")),\n      menuItem(\"N-grams & Phrases\", tabName = \"ngrams\", icon = icon(\"link\")),\n      menuItem(\"Document-Term Matrix\", tabName = \"dtm\", icon = icon(\"table\")),\n      menuItem(\"Practice Lab\", tabName = \"practice\", icon = icon(\"laptop-code\")),\n      menuItem(\"Resources\", tabName = \"resources\", icon = icon(\"bookmark\"))\n    )\n  ),\n  \n  dashboardBody(\n    tags$head(\n      tags$style(HTML(\"\n        .content-wrapper, .right-side {\n          background-color: #f8f9fa;\n        }\n        .code-output {\n          background-color: #f8f9fa;\n          border: 1px solid #dee2e6;\n          border-radius: 4px;\n          padding: 10px;\n          font-family: 'Courier New', monospace;\n          white-space: pre-wrap;\n        }\n        .exercise-box {\n          background-color: #e8f5e8;\n          border-left: 4px solid #4caf50;\n          padding: 15px;\n          margin: 10px 0;\n        }\n        .tip-box {\n          background-color: #fff3e0;\n          border-left: 4px solid #ff9800;\n          padding: 10px;\n          margin: 10px 0;\n        }\n        .warning-box {\n          background-color: #ffebee;\n          border-left: 4px solid #f44336;\n          padding: 10px;\n          margin: 10px 0;\n        }\n        textarea {\n          font-family: 'Courier New', monospace;\n          font-size: 12px;\n        }\n      \"))\n    ),\n    \n    tabItems(\n      # Introduction Tab\n      tabItem(\n        tabName = \"intro\",\n        fluidRow(\n          box(\n            title = \"Welcome to Text Mining with R!\", status = \"primary\", solidHeader = TRUE, width = 12,\n            h3(\"What is Text Mining?\"),\n            p(\"Text mining (also called text analytics) is the process of extracting meaningful information \n              from unstructured text data. It combines techniques from statistics, linguistics, and machine learning.\"),\n            \n            h4(\"What Can You Do with Text Mining?\"),\n            tags$ul(\n              tags$li(\"Analyze customer feedback and reviews\"),\n              tags$li(\"Study social media sentiment\"),\n              tags$li(\"Extract topics from documents\"),\n              tags$li(\"Classify documents automatically\"),\n              tags$li(\"Find patterns in literature or news\"),\n              tags$li(\"Create word clouds and visualizations\")\n            ),\n            \n            h4(\"R Packages for Text Mining\"),\n            p(\"R has excellent packages for text analysis:\"),\n            tags$ul(\n              tags$li(strong(\"tm\"), \" - Traditional text mining framework\"),\n              tags$li(strong(\"tidytext\"), \" - Tidy approach to text analysis\"),\n              tags$li(strong(\"wordcloud\"), \" - Create beautiful word clouds\"),\n              tags$li(strong(\"stringr\"), \" - String manipulation\"),\n              tags$li(strong(\"SnowballC\"), \" - Text stemming\")\n            )\n          )\n        ),\n        \n        fluidRow(\n          box(\n            title = \"Your First Text Analysis\", status = \"success\", solidHeader = TRUE, width = 6,\n            p(\"Let's start by analyzing a simple text:\"),\n            div(class = \"exercise-box\",\n                strong(\"Try this: \"), \"Count words in a sentence\"\n            ),\n            create_code_input(\"intro_code\", \n                     value = \"# Your first text analysis\\ntext <- \\\"Text mining is fun and useful for data science\\\"\\n\\n# Split into words\\nwords <- strsplit(text, \\\" \\\")[[1]]\\nprint(words)\\n\\n# Count words\\nlength(words)\", \n                     height = \"150px\"),\n            br(),\n            actionButton(\"run_intro\", \"Run Code\", class = \"btn-success\"),\n            br(), br(),\n            h5(\"Output:\"),\n            verbatimTextOutput(\"intro_output\")\n          ),\n          \n          box(\n            title = \"Text Mining Workflow\", status = \"info\", solidHeader = TRUE, width = 6,\n            h5(\"Typical Steps in Text Mining:\"),\n            tags$ol(\n              tags$li(\"Data Collection\"),\n              tags$li(\"Text Preprocessing\"),\n              tags$li(\"Tokenization\"),\n              tags$li(\"Cleaning (remove stopwords, punctuation)\"),\n              tags$li(\"Analysis (frequency, sentiment, topics)\"),\n              tags$li(\"Visualization and Interpretation\")\n            ),\n            div(class = \"tip-box\",\n                strong(\"Tip: \"), \"Most time in text mining is spent on preprocessing and cleaning!\"\n            )\n          )\n        )\n      ),\n      \n      # Text Basics Tab\n      tabItem(\n        tabName = \"basics\",\n        fluidRow(\n          box(\n            title = \"Working with Text in R\", status = \"primary\", solidHeader = TRUE, width = 12,\n            h4(\"Basic Text Operations\"),\n            p(\"Before we dive into complex analysis, let's learn basic text manipulation in R:\"),\n            \n            fluidRow(\n              column(6,\n                h5(\"String Functions:\"),\n                tags$pre(\n\"# Basic string operations\nnchar(text)          # Count characters\ntoupper(text)        # Convert to uppercase\ntolower(text)        # Convert to lowercase\nsubstr(text, 1, 5)   # Extract substring\npaste(a, b, sep=' ') # Combine strings\"\n                )\n              ),\n              column(6,\n                h5(\"Pattern Matching:\"),\n                tags$pre(\n\"# Find and replace patterns\ngrep('pattern', text)      # Find pattern\ngsub('old', 'new', text)   # Replace pattern\nstr_detect(text, 'word')   # Detect word\nstr_count(text, 'word')    # Count occurrences\"\n                )\n              )\n            )\n          )\n        ),\n        \n        fluidRow(\n          box(\n            title = \"Practice Text Operations\", status = \"success\", solidHeader = TRUE, width = 12,\n            fluidRow(\n              column(6,\n                create_code_input(\"basics_code\", \n                         value = \"# Sample text\\nmy_text <- \\\"R is great for Data Science and Text Mining!\\\"\\n\\n# Basic operations\\nprint(paste(\\\"Original:\\\", my_text))\\nprint(paste(\\\"Length:\\\", nchar(my_text)))\\nprint(paste(\\\"Lowercase:\\\", tolower(my_text)))\\nprint(paste(\\\"First 10 chars:\\\", substr(my_text, 1, 10)))\\n\\n# Count specific words\\nif (requireNamespace('stringr', quietly = TRUE)) {\\n  library(stringr)\\n  print(paste(\\\"Count of 'a':\\\", str_count(tolower(my_text), \\\"a\\\")))\\n} else {\\n  print(\\\"stringr package not available\\\")\\n}\", \n                         height = \"350px\")\n              ),\n              column(6,\n                br(),\n                actionButton(\"run_basics\", \"Run Code\", class = \"btn-success\"),\n                br(), br(),\n                h5(\"Output:\"),\n                verbatimTextOutput(\"basics_output\")\n              )\n            )\n          )\n        )\n      ),\n      \n      # Text Preprocessing Tab\n      tabItem(\n        tabName = \"preprocessing\",\n        fluidRow(\n          box(\n            title = \"Text Preprocessing\", status = \"primary\", solidHeader = TRUE, width = 12,\n            h4(\"Why Preprocess Text?\"),\n            p(\"Raw text contains noise that can interfere with analysis. Preprocessing cleans and standardizes text:\"),\n            \n            tags$ul(\n              tags$li(\"Remove punctuation and special characters\"),\n              tags$li(\"Convert to lowercase\"),\n              tags$li(\"Remove stopwords (common words like 'the', 'and')\"),\n              tags$li(\"Remove extra whitespace\"),\n              tags$li(\"Stem or lemmatize words\")\n            )\n          )\n        ),\n        \n        fluidRow(\n          box(\n            title = \"Preprocessing Functions\", status = \"warning\", solidHeader = TRUE, width = 6,\n            h5(\"Common Preprocessing Steps:\"),\n            tags$pre(\n\"# Load required libraries\nlibrary(tm)\nlibrary(stringr)\n\n# Remove punctuation\nremovePunctuation(text)\n\n# Remove numbers  \nremoveNumbers(text)\n\n# Remove stopwords\nremoveWords(text, stopwords('english'))\n\n# Strip whitespace\nstripWhitespace(text)\n\n# Stemming\nstemDocument(text)\"\n            )\n          ),\n          \n          box(\n            title = \"Interactive Preprocessing\", status = \"success\", solidHeader = TRUE, width = 6,\n            create_code_input(\"preprocess_code\", \n                     value = \"# Sample messy text\\nraw_text <- \\\"Hello!!! This is SAMPLE text with 123 numbers, punctuation... and LOTS of issues???\\\"\\n\\n# Step by step cleaning\\nstep1 <- tolower(raw_text)\\n\\n# Basic punctuation removal if tm not available\\nif (requireNamespace('tm', quietly = TRUE)) {\\n  library(tm)\\n  step2 <- removePunctuation(step1)\\n  step3 <- removeNumbers(step2)\\n  step4 <- stripWhitespace(step3)\\n} else {\\n  # Manual cleaning\\n  step2 <- gsub('[[:punct:]]', ' ', step1)\\n  step3 <- gsub('[[:digit:]]', ' ', step2)\\n  step4 <- gsub('\\\\\\\\s+', ' ', trimws(step3))\\n}\\n\\nprint(paste(\\\"Original:\\\", raw_text))\\nprint(paste(\\\"Cleaned:\\\", step4))\\n\\n# Remove stopwords\\nbasic_stopwords <- c('the', 'and', 'is', 'this', 'with', 'of', 'a', 'an')\\nwords <- strsplit(step4, \\\" \\\")[[1]]\\ncleaned_words <- words[!words %in% basic_stopwords & words != \\\"\\\"]\\nfinal_text <- paste(cleaned_words, collapse = \\\" \\\")\\nprint(paste(\\\"No stopwords:\\\", final_text))\", \n                     height = \"350px\"),\n            br(),\n            actionButton(\"run_preprocess\", \"Run Code\", class = \"btn-success\")\n          )\n        ),\n        \n        fluidRow(\n          box(\n            title = \"Preprocessing Output\", status = \"info\", solidHeader = TRUE, width = 12,\n            verbatimTextOutput(\"preprocess_output\"),\n            br(),\n            div(class = \"tip-box\",\n                strong(\"Best Practice: \"), \"Always examine your text before and after preprocessing to ensure you're not removing important information!\"\n            )\n          )\n        )\n      ),\n      \n      # Word Frequency Tab\n      tabItem(\n        tabName = \"frequency\",\n        fluidRow(\n          box(\n            title = \"Word Frequency Analysis\", status = \"primary\", solidHeader = TRUE, width = 12,\n            h4(\"Understanding Word Frequencies\"),\n            p(\"Word frequency analysis reveals which words appear most often in your text. \n              This is fundamental to many text mining applications.\"),\n            \n            h5(\"Methods for Frequency Analysis:\"),\n            tags$ul(\n              tags$li(\"Simple word counting\"),\n              tags$li(\"Term frequency (TF)\"),\n              tags$li(\"Term frequency-inverse document frequency (TF-IDF)\"),\n              tags$li(\"Frequency plots and charts\")\n            )\n          )\n        ),\n        \n        fluidRow(\n          box(\n            title = \"Create Frequency Analysis\", status = \"success\", solidHeader = TRUE, width = 6,\n            create_code_input(\"frequency_code\", \n                     value = \"# Sample text corpus\\ntexts <- c(\\n  \\\"Text mining is the process of deriving information from text\\\",\\n  \\\"Data science involves analyzing data to extract insights\\\", \\n  \\\"Machine learning helps in analyzing patterns in data\\\",\\n  \\\"Text analysis is important for understanding documents\\\"\\n)\\n\\n# Combine all texts\\nall_text <- paste(texts, collapse = \\\" \\\")\\n\\n# Basic preprocessing\\ncleaned <- tolower(all_text)\\n# Manual punctuation removal\\ncleaned <- gsub('[[:punct:]]', ' ', cleaned)\\n# Split into words\\nwords <- strsplit(cleaned, \\\"\\\\\\\\s+\\\")[[1]]\\n\\n# Remove empty strings and basic stopwords\\nbasic_stopwords <- c('the', 'is', 'of', 'to', 'and', 'in', 'for', 'from')\\nwords <- words[words != \\\"\\\" & !words %in% basic_stopwords]\\n\\n# Count frequency\\nword_freq <- table(words)\\nword_freq_sorted <- sort(word_freq, decreasing = TRUE)\\n\\nprint(\\\"Top 10 most frequent words:\\\")\\nprint(head(word_freq_sorted, 10))\", \n                     height = \"400px\"),\n            br(),\n            actionButton(\"run_frequency\", \"Run Code\", class = \"btn-success\")\n          ),\n          \n          box(\n            title = \"Frequency Results & Plot\", status = \"info\", solidHeader = TRUE, width = 6,\n            verbatimTextOutput(\"frequency_output\"),\n            br(),\n            plotOutput(\"frequency_plot\", height = \"250px\")\n          )\n        )\n      ),\n      \n      # Word Cloud Tab\n      tabItem(\n        tabName = \"wordcloud\",\n        fluidRow(\n          box(\n            title = \"Word Clouds\", status = \"primary\", solidHeader = TRUE, width = 12,\n            h4(\"Visualizing Text with Word Clouds\"),\n            p(\"Word clouds provide an intuitive way to visualize word frequencies. \n              Larger words appear more frequently in the text.\"),\n            \n            div(class = \"warning-box\",\n                strong(\"Note: \"), \"Word clouds are great for exploration but should be supplemented with quantitative analysis for serious research.\"\n            )\n          )\n        ),\n        \n        fluidRow(\n          box(\n            title = \"Create Your Word Cloud\", status = \"success\", solidHeader = TRUE, width = 6,\n            h5(\"Sample Text Options:\"),\n            selectInput(\"text_source\", \"Choose text source:\",\n                       choices = list(\n                         \"Sample Data Science Text\" = \"datasci\",\n                         \"Literature Sample\" = \"literature\", \n                         \"Custom Text\" = \"custom\"\n                       )),\n            \n            conditionalPanel(\n              condition = \"input.text_source == 'custom'\",\n              textAreaInput(\"custom_text\", \"Enter your text:\",\n                           value = \"Enter your own text here for analysis...\",\n                           rows = 5, width = \"100%\")\n            ),\n            \n            h5(\"Word Cloud Settings:\"),\n            sliderInput(\"max_words\", \"Maximum words:\", min = 10, max = 100, value = 50),\n            selectInput(\"color_palette\", \"Color scheme:\",\n                       choices = list(\"Dark2\", \"Set1\", \"Pastel1\", \"Blues\")),\n            br(),\n            actionButton(\"create_wordcloud\", \"Create Word Cloud\", class = \"btn-success\")\n          ),\n          \n          box(\n            title = \"Your Word Cloud\", status = \"info\", solidHeader = TRUE, width = 6,\n            plotOutput(\"wordcloud_plot\", height = \"400px\")\n          )\n        )\n      ),\n      \n      # Practice Lab Tab\n      tabItem(\n        tabName = \"practice\",\n        fluidRow(\n          box(\n            title = \"Text Mining Practice Lab\", status = \"primary\", solidHeader = TRUE, width = 12,\n            h4(\"Apply Your Knowledge\"),\n            p(\"Use this area to practice text mining techniques. Try these challenges:\"),\n            \n            div(class = \"exercise-box\",\n                h5(\"Challenge 1: Text Cleaning\"),\n                p(\"Clean this messy text: 'Hello!!! This is 123 MESSY text with punctuation... Clean it up!'\")\n            ),\n            \n            div(class = \"exercise-box\",\n                h5(\"Challenge 2: Frequency Analysis\"),\n                p(\"Find the top 5 most common words in a collection of sentences (excluding stopwords).\")\n            ),\n            \n            div(class = \"exercise-box\",\n                h5(\"Challenge 3: Simple Pattern Matching\"),\n                p(\"Count how many times specific words appear in text using grep or string functions.\")\n            ),\n            \n            div(class = \"exercise-box\",\n                h5(\"Challenge 4: Basic Text Statistics\"),\n                p(\"Calculate text statistics: number of characters, words, and sentences.\")\n            )\n          )\n        ),\n        \n        fluidRow(\n          box(\n            title = \"Your Code\", status = \"success\", solidHeader = TRUE, width = 6,\n            create_code_input(\"practice_code\", \n                     value = \"# Practice area - write your text mining code here\\n# Try the challenges above!\\n\\n# Challenge 1 example:\\nmessy_text <- \\\"Hello!!! This is 123 MESSY text with punctuation... Clean it up!\\\"\\n\\n# Your solution here:\\ncleaned <- tolower(messy_text)\\ncleaned <- gsub('[[:punct:]]', ' ', cleaned)\\ncleaned <- gsub('[[:digit:]]', ' ', cleaned)\\ncleaned <- gsub('\\\\\\\\s+', ' ', trimws(cleaned))\\n\\nprint(paste(\\\"Original:\\\", messy_text))\\nprint(paste(\\\"Cleaned:\\\", cleaned))\", \n                     height = \"450px\"),\n            br(),\n            actionButton(\"run_practice\", \"Run Code\", class = \"btn-success\"),\n            br(),\n            actionButton(\"clear_practice\", \"Clear Code\", class = \"btn-warning\")\n          ),\n          \n          box(\n            title = \"Output & Notes\", status = \"info\", solidHeader = TRUE, width = 6,\n            verbatimTextOutput(\"practice_output\"),\n            br(),\n            h5(\"Quick Reference:\"),\n            tags$ul(\n              tags$li(\"tolower(), toupper()\"),\n              tags$li(\"gsub(), grep()\"),\n              tags$li(\"strsplit(), paste()\"),\n              tags$li(\"table(), sort()\")\n            ),\n            br(),\n            div(class = \"tip-box\",\n                strong(\"Note: \"), \"This version works with base R functions when specialized text mining packages are not available.\"\n            )\n          )\n        )\n      ),\n      \n      # Resources Tab\n      tabItem(\n        tabName = \"resources\",\n        fluidRow(\n          box(\n            title = \"Text Mining Resources\", status = \"primary\", solidHeader = TRUE, width = 12,\n            \n            fluidRow(\n              column(6,\n                h4(\"Essential R Packages\"),\n                tags$ul(\n                  tags$li(strong(\"tm\"), \" - Traditional text mining framework\"),\n                  tags$li(strong(\"tidytext\"), \" - Tidy text mining approach\"),\n                  tags$li(strong(\"stringr\"), \" - String manipulation\"),\n                  tags$li(strong(\"wordcloud\"), \" - Word cloud generation\"),\n                  tags$li(strong(\"SnowballC\"), \" - Stemming algorithms\"),\n                  tags$li(strong(\"textdata\"), \" - Sentiment lexicons\")\n                ),\n                \n                h4(\"Installation Commands\"),\n                tags$pre(\n\"# Install all at once:\ninstall.packages(c(\n  'tm', 'tidytext', 'stringr', \n  'wordcloud', 'SnowballC',\n  'shinyAce'\n))\"\n                )\n              ),\n              \n              column(6,\n                h4(\"Base R Text Functions\"),\n                tags$pre(\n\"# String manipulation\nnchar(), substr(), paste()\ntoupper(), tolower()\ngrep(), gsub(), grepl()\nstrsplit(), trimws()\n\n# Pattern matching\n[[:punct:]]  # Punctuation\n[[:digit:]]  # Numbers\n[[:alpha:]]  # Letters\n\\\\\\\\s+        # Whitespace\"\n                ),\n                \n                h4(\"Common Tasks\"),\n                tags$ul(\n                  tags$li(\"Text cleaning and preprocessing\"),\n                  tags$li(\"Word frequency analysis\"),\n                  tags$li(\"Sentiment analysis\"),\n                  tags$li(\"Document classification\"),\n                  tags$li(\"Topic modeling\")\n                )\n              )\n            )\n          )\n        ),\n        \n        fluidRow(\n          box(\n            title = \"Package Installation Help\", status = \"warning\", solidHeader = TRUE, width = 6,\n            h5(\"If packages are missing:\"),\n            tags$ol(\n              tags$li(\"Run: install.packages('package_name')\"),\n              tags$li(\"Restart R session\"),\n              tags$li(\"Try library(package_name)\"),\n              tags$li(\"Check for error messages\")\n            ),\n            \n            div(class = \"tip-box\",\n                strong(\"Tip: \"), \"Some packages may require additional system dependencies on Linux/Mac.\"\n            )\n          ),\n          \n          box(\n            title = \"Next Steps\", status = \"success\", solidHeader = TRUE, width = 6,\n            h5(\"Continue Learning:\"),\n            tags$ul(\n              tags$li(\"Practice with real text data\"),\n              tags$li(\"Learn advanced preprocessing techniques\"),\n              tags$li(\"Explore sentiment analysis methods\"),\n              tags$li(\"Study topic modeling with LDA\"),\n              tags$li(\"Try text classification algorithms\")\n            ),\n            \n            h5(\"Useful Datasets:\"),\n            tags$ul(\n              tags$li(\"Built-in R datasets with text\"),\n              tags$li(\"Movie reviews for sentiment\"),\n              tags$li(\"News articles for topic modeling\"),\n              tags$li(\"Customer reviews for business analysis\")\n            )\n          )\n        )\n      )\n    )\n  )\n)\n\n# Define Server Logic\nserver <- function(input, output, session) {\n  \n  # Introduction tab\n  observeEvent(input$run_intro, {\n    output$intro_output <- renderText({\n      tryCatch({\n        result <- capture.output({\n          eval(parse(text = input$intro_code))\n        })\n        paste(result, collapse = \"\\n\")\n      }, error = function(e) {\n        paste(\"Error:\", e$message)\n      })\n    })\n  })\n  \n  # Basic operations tab\n  observeEvent(input$run_basics, {\n    output$basics_output <- renderText({\n      tryCatch({\n        result <- capture.output({\n          eval(parse(text = input$basics_code))\n        })\n        paste(result, collapse = \"\\n\")\n      }, error = function(e) {\n        paste(\"Error:\", e$message)\n      })\n    })\n  })\n  \n  # Preprocessing tab\n  observeEvent(input$run_preprocess, {\n    output$preprocess_output <- renderText({\n      tryCatch({\n        result <- capture.output({\n          eval(parse(text = input$preprocess_code))\n        })\n        paste(result, collapse = \"\\n\")\n      }, error = function(e) {\n        paste(\"Error:\", e$message)\n      })\n    })\n  })\n  \n  # Frequency analysis tab\n  observeEvent(input$run_frequency, {\n    output$frequency_output <- renderText({\n      tryCatch({\n        result <- capture.output({\n          eval(parse(text = input$frequency_code))\n        })\n        paste(result, collapse = \"\\n\")\n      }, error = function(e) {\n        paste(\"Error:\", e$message)\n      })\n    })\n    \n    # Create frequency plot\n    output$frequency_plot <- renderPlot({\n      tryCatch({\n        # Re-run the analysis to get data\n        eval(parse(text = input$frequency_code))\n        \n        # Create plot data\n        if (exists(\"word_freq_sorted\") && length(word_freq_sorted) > 0) {\n          freq_df <- data.frame(\n            word = names(head(word_freq_sorted, 8)),\n            frequency = as.numeric(head(word_freq_sorted, 8))\n          )\n          \n          if (requireNamespace(\"ggplot2\", quietly = TRUE)) {\n            library(ggplot2)\n            ggplot(freq_df, aes(x = reorder(word, frequency), y = frequency)) +\n              geom_col(fill = \"steelblue\", alpha = 0.7) +\n              coord_flip() +\n              labs(title = \"Top 8 Most Frequent Words\", \n                   x = \"Words\", y = \"Frequency\") +\n              theme_minimal()\n          } else {\n            # Fallback to base R plot\n            barplot(freq_df$frequency, names.arg = freq_df$word,\n                   main = \"Word Frequencies\", horiz = TRUE, las = 1,\n                   col = \"steelblue\")\n          }\n        }\n      }, error = function(e) {\n        plot.new()\n        text(0.5, 0.5, paste(\"Error:\", e$message), cex = 1.2, col = \"red\")\n      })\n    })\n  })\n  \n  # Word cloud tab\n  observeEvent(input$create_wordcloud, {\n    output$wordcloud_plot <- renderPlot({\n      tryCatch({\n        # Get text based on selection\n        if (input$text_source == \"datasci\") {\n          text_data <- \"Data science is an interdisciplinary field that uses scientific methods processes algorithms and systems to extract knowledge and insights from structured and unstructured data. Machine learning artificial intelligence statistics and big data analytics are core components of data science\"\n        } else if (input$text_source == \"literature\") {\n          text_data <- \"It was the best of times it was the worst of times it was the age of wisdom it was the age of foolishness it was the epoch of belief it was the epoch of incredulity it was the season of light it was the season of darkness\"\n        } else {\n          text_data <- input$custom_text\n        }\n        \n        # Preprocess text\n        text_clean <- tolower(text_data)\n        text_clean <- gsub('[[:punct:]]', ' ', text_clean)\n        text_clean <- gsub('[[:digit:]]', ' ', text_clean)\n        words <- strsplit(text_clean, \"\\\\s+\")[[1]]\n        \n        # Basic stopwords\n        basic_stopwords <- c(\"the\", \"and\", \"is\", \"it\", \"was\", \"of\", \"to\", \"a\", \"an\", \"in\", \"on\", \"at\", \"for\", \"with\", \"by\")\n        words <- words[!words %in% basic_stopwords & words != \"\"]\n        \n        # Calculate frequencies\n        word_freq <- table(words)\n        \n        # Create word cloud\n        if (requireNamespace(\"wordcloud\", quietly = TRUE) && length(word_freq) > 0) {\n          library(wordcloud)\n          library(RColorBrewer)\n          \n          wordcloud(names(word_freq), freq = word_freq, \n                   max.words = input$max_words,\n                   colors = brewer.pal(8, input$color_palette),\n                   random.order = FALSE,\n                   rot.per = 0.3,\n                   scale = c(3, 0.5))\n        } else {\n          # Fallback visualization\n          if (length(word_freq) > 0) {\n            top_words <- head(sort(word_freq, decreasing = TRUE), 20)\n            barplot(top_words, main = \"Word Frequencies (wordcloud package not available)\",\n                   las = 2, col = rainbow(length(top_words)))\n          } else {\n            plot.new()\n            text(0.5, 0.5, \"No words to display\", cex = 1.5)\n          }\n        }\n      }, error = function(e) {\n        plot.new()\n        text(0.5, 0.5, paste(\"Error:\", e$message), cex = 1.2, col = \"red\")\n      })\n    })\n  })\n  \n  # Practice lab\n  observeEvent(input$run_practice, {\n    output$practice_output <- renderText({\n      tryCatch({\n        if (input$practice_code == \"\" || trimws(input$practice_code) == \"\") {\n          \"Write some text mining code and click 'Run Code' to see the output!\"\n        } else {\n          result <- capture.output({\n            eval(parse(text = input$practice_code))\n          })\n          paste(result, collapse = \"\\n\")\n        }\n      }, error = function(e) {\n        paste(\"Error:\", e$message, \"\\n\\nTip: Check your syntax and make sure all quotes and parentheses are balanced.\")\n      })\n    })\n  })\n  \n  observeEvent(input$clear_practice, {\n    if (use_ace) {\n      updateAceEditor(session, \"practice_code\", \n                     value = \"# Practice area - write your text mining code here\\n# Try the challenges above!\\n\\n# Challenge 1 example:\\nmessy_text <- \\\"Hello!!! This is 123 MESSY text with punctuation... Clean it up!\\\"\\n\\n# Your solution here:\\ncleaned <- tolower(messy_text)\\ncleaned <- gsub('[[:punct:]]', ' ', cleaned)\\ncleaned <- gsub('[[:digit:]]', ' ', cleaned)\\ncleaned <- gsub('\\\\\\\\s+', ' ', trimws(cleaned))\\n\\nprint(paste(\\\"Original:\\\", messy_text))\\nprint(paste(\\\"Cleaned:\\\", cleaned))\")\n    } else {\n      updateTextAreaInput(session, \"practice_code\", \n                         value = \"# Practice area - write your text mining code here\\n# Try the challenges above!\\n\\n# Challenge 1 example:\\nmessy_text <- \\\"Hello!!! This is 123 MESSY text with punctuation... Clean it up!\\\"\\n\\n# Your solution here:\\ncleaned <- tolower(messy_text)\\ncleaned <- gsub('[[:punct:]]', ' ', cleaned)\\ncleaned <- gsub('[[:digit:]]', ' ', cleaned)\\ncleaned <- gsub('\\\\\\\\s+', ' ', trimws(cleaned))\\n\\nprint(paste(\\\"Original:\\\", messy_text))\\nprint(paste(\\\"Cleaned:\\\", cleaned))\")\n    }\n    output$practice_output <- renderText(\"\")\n  })\n}\n\n# Run the application\nshinyApp(ui = ui, server = server)","type":"text"}]
